{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":24141,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.utils.multiclass import unique_labels\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-03T01:00:41.696376Z","iopub.execute_input":"2024-06-03T01:00:41.696732Z","iopub.status.idle":"2024-06-03T01:00:41.999090Z","shell.execute_reply.started":"2024-06-03T01:00:41.696683Z","shell.execute_reply":"2024-06-03T01:00:41.998083Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Import standard libraries\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n''' to learn more about itertools visit\n    https://medium.com/@jasonrigden/a-guide-to-python-itertools-82e5a306cdf8'''\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:00:44.134740Z","iopub.execute_input":"2024-06-03T01:00:44.135119Z","iopub.status.idle":"2024-06-03T01:00:44.887054Z","shell.execute_reply.started":"2024-06-03T01:00:44.135051Z","shell.execute_reply":"2024-06-03T01:00:44.886451Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Import keras functions\n\nfrom keras import Sequential\n\n'''Since we are using transfer learning let's import the model that we want to implement.Let's use VGG 19(19 layers) and Resnet-50 (50 layers of residual units). \nResidual units allow us to add more layers onto the model without a degradation in accuracy.\nLet's try and compare the accuracy of the 2 models and see if the addtional layers do make a significant difference. '''\n\nfrom keras.applications import VGG19,ResNet50\n\n'Import the datagenerator to augment images'\nfrom keras.preprocessing.image import ImageDataGenerator\n\n'''Import the optimizers and leanring rate annealer (which will reduce the learning rate once a particular metric we choose(in this case validation error) \ndoes not reduce after a user defined number of epochs)'''\nfrom keras.optimizers import SGD,Adam\nfrom keras.callbacks import ReduceLROnPlateau\n\n'Lastly import the final layers that will be added on top of the base model'\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n\n'Import to_categorical from the keras utils package to one hot encode the labels'\nfrom keras.utils import to_categorical","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2024-06-03T01:00:47.072534Z","iopub.execute_input":"2024-06-03T01:00:47.072858Z","iopub.status.idle":"2024-06-03T01:00:49.584641Z","shell.execute_reply.started":"2024-06-03T01:00:47.072809Z","shell.execute_reply":"2024-06-03T01:00:49.583914Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Import dataset\nfrom keras.datasets import cifar100","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:00:53.629056Z","iopub.execute_input":"2024-06-03T01:00:53.629344Z","iopub.status.idle":"2024-06-03T01:00:53.633337Z","shell.execute_reply.started":"2024-06-03T01:00:53.629302Z","shell.execute_reply":"2024-06-03T01:00:53.632272Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Divide the data in Train, Validation and Test Datasets\n'I had to turn the Internet setting to on to download load the dataset'\n(x_train,y_train),(x_test,y_test)=cifar100.load_data()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:00.305876Z","iopub.execute_input":"2024-06-03T01:01:00.306175Z","iopub.status.idle":"2024-06-03T01:01:01.471507Z","shell.execute_reply.started":"2024-06-03T01:01:00.306115Z","shell.execute_reply":"2024-06-03T01:01:01.470771Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:03.170146Z","iopub.execute_input":"2024-06-03T01:01:03.170429Z","iopub.status.idle":"2024-06-03T01:01:04.155128Z","shell.execute_reply.started":"2024-06-03T01:01:03.170385Z","shell.execute_reply":"2024-06-03T01:01:04.154206Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Print the dimensions of the datasets to make sure everything's kosher\n\nprint((x_train.shape,y_train.shape))\nprint((x_val.shape,y_val.shape))\nprint((x_test.shape,y_test.shape))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:07.289212Z","iopub.execute_input":"2024-06-03T01:01:07.289514Z","iopub.status.idle":"2024-06-03T01:01:07.295371Z","shell.execute_reply.started":"2024-06-03T01:01:07.289455Z","shell.execute_reply":"2024-06-03T01:01:07.294414Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"((35000, 32, 32, 3), (35000, 1))\n((15000, 32, 32, 3), (15000, 1))\n((10000, 32, 32, 3), (10000, 1))\n","output_type":"stream"}]},{"cell_type":"code","source":"#One hot encode the labels.Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n\ny_train=to_categorical(y_train)\ny_val=to_categorical(y_val)\ny_test=to_categorical(y_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:09.970057Z","iopub.execute_input":"2024-06-03T01:01:09.970394Z","iopub.status.idle":"2024-06-03T01:01:09.990468Z","shell.execute_reply.started":"2024-06-03T01:01:09.970330Z","shell.execute_reply":"2024-06-03T01:01:09.989615Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Lets print the dimensions one more time to see if things changed the way we expected\n\nprint((x_train.shape,y_train.shape))\nprint((x_val.shape,y_val.shape))\nprint((x_test.shape,y_test.shape))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:12.998930Z","iopub.execute_input":"2024-06-03T01:01:12.999267Z","iopub.status.idle":"2024-06-03T01:01:13.004266Z","shell.execute_reply.started":"2024-06-03T01:01:12.999196Z","shell.execute_reply":"2024-06-03T01:01:13.003307Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"((35000, 32, 32, 3), (35000, 100))\n((15000, 32, 32, 3), (15000, 100))\n((10000, 32, 32, 3), (10000, 100))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can now begin the actual process of model building.I find that following a set process and following consistently makes learning this easier.So here is the process I follow:\n\n*  Define the Data Augmentation (ImageDataGenerator) and Learning Rate Annealer (ReduceOnPlateau) functions\n*  Build the model (Base Model + Flatten + Dense)\n*  Check model summary\n*  Initialize Batch Size,Number of Epochs\n*  Compile model\n*  Fit the model (We will use fit_generator since the data is fed to the model using an augmentation function\n*  Evaluate the model on test data\n","metadata":{}},{"cell_type":"code","source":"#Data Augmentation Function: Let's define an instance of the ImageDataGenerator class and set the parameters.We have to instantiate for the Train,Validation and Test datasets\ntrain_generator = ImageDataGenerator(\n                                    rotation_range=2, \n                                    horizontal_flip=True,\n                                    zoom_range=.1 )\n\nval_generator = ImageDataGenerator(\n                                    rotation_range=2, \n                                    horizontal_flip=True,\n                                    zoom_range=.1)\n\ntest_generator = ImageDataGenerator(\n                                    rotation_range=2, \n                                    horizontal_flip= True,\n                                    zoom_range=.1) \n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:15.896154Z","iopub.execute_input":"2024-06-03T01:01:15.896501Z","iopub.status.idle":"2024-06-03T01:01:15.902658Z","shell.execute_reply.started":"2024-06-03T01:01:15.896426Z","shell.execute_reply":"2024-06-03T01:01:15.901702Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Fit the augmentation method to the data\n\ntrain_generator.fit(x_train)\nval_generator.fit(x_val)\ntest_generator.fit(x_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:20.317218Z","iopub.execute_input":"2024-06-03T01:01:20.317523Z","iopub.status.idle":"2024-06-03T01:01:21.485736Z","shell.execute_reply.started":"2024-06-03T01:01:20.317454Z","shell.execute_reply":"2024-06-03T01:01:21.484914Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"It's not necessary to use a data generator for validation data while fitting the model, however I find that it gives better validation accuracy if it is used.This is probably because themodel can learn more generalized features if validation data is also augmented.\nIve used only a few of the many available functionalities of the augment function.To know more about the capabilities read this article:\nhttps://towardsdatascience.com/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085\n","metadata":{}},{"cell_type":"code","source":"'''Learning Rate Annealer: The learning rate can be modified after a set number of epochs or after a certain condition is met. We will use the latter and change the learning rate if \nthe validation error does not reduce after a set number of epochs. To do this we will use the patience parameter.'''\n\nlrr= ReduceLROnPlateau(\n                       monitor='val_acc', #Metric to be measured\n                       factor=.01, #Factor by which learning rate will be reduced\n                       patience=3,  #No. of epochs after which if there is no improvement in the val_acc, the learning rate is reduced\n                       min_lr=1e-5) #The minimum learning rate ","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:24.279407Z","iopub.execute_input":"2024-06-03T01:01:24.279782Z","iopub.status.idle":"2024-06-03T01:01:24.284433Z","shell.execute_reply.started":"2024-06-03T01:01:24.279710Z","shell.execute_reply":"2024-06-03T01:01:24.283610Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Build the model\n\nbase_model_1 = ResNet50(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])\nbase_model_2 = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:09:33.334314Z","iopub.execute_input":"2024-06-03T01:09:33.334695Z","iopub.status.idle":"2024-06-03T01:10:00.430183Z","shell.execute_reply.started":"2024-06-03T01:09:33.334647Z","shell.execute_reply":"2024-06-03T01:10:00.429499Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size= 100\nepochs=10","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:50.768801Z","iopub.execute_input":"2024-06-03T01:01:50.769127Z","iopub.status.idle":"2024-06-03T01:01:50.773388Z","shell.execute_reply.started":"2024-06-03T01:01:50.769066Z","shell.execute_reply":"2024-06-03T01:01:50.772349Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"The next step is to define the learning rate for the optimizer we will use. I have chosen the SGD and Adam optimizer. The main difference between the 2 is that SGD uses the same learning rate for all parameters and updates all of them by the same amount. The learning rate does not change during training. Adam stands for Adaptive Moment estimation and maintains a separate learning rate for each parameter and updates them separately.\n\nTo understand this concept more please read this article:\nhttps://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/","metadata":{}},{"cell_type":"code","source":"learn_rate=.001\n\nsgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\nadam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:01:56.116917Z","iopub.execute_input":"2024-06-03T01:01:56.117225Z","iopub.status.idle":"2024-06-03T01:01:56.154021Z","shell.execute_reply.started":"2024-06-03T01:01:56.117180Z","shell.execute_reply":"2024-06-03T01:01:56.153138Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Since we're using a function to generate data, we have to use the argument fit_generator. Both the train data and the validation data will be generated using the augmentation methods we have previously defined. To use the fit_generator function we will define the following parameters:\n\ngenerator.flow(x_train,y_train,batch_size)\n\nHere we use generator.flow since the data is being generated from a numpy array. You could also have data available in folders in which case we would use flow_from_directory in which case the class names are inferred directly from the folder names within the train data folder\n\nMore information on this can be found by reading the official documentation:\nhttps://keras.io/preprocessing/image/\n\n","metadata":{}},{"cell_type":"markdown","source":"Now that we have our code for the confusion matrix, let's make predictions on the test set and see how this model has performed","metadata":{}},{"cell_type":"code","source":"class_names = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', \n                    'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', \n                    'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', \n                    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', \n                    'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', \n                    'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n                    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', \n                    'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', \n                    'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:49:58.219099Z","iopub.execute_input":"2024-06-03T00:49:58.219372Z","iopub.status.idle":"2024-06-03T00:49:58.231362Z","shell.execute_reply.started":"2024-06-03T00:49:58.219322Z","shell.execute_reply":"2024-06-03T00:49:58.230725Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"To compare this with another model, let's try and use Resnet-50. Residual nets allow us to add deeper layers to the network, without having the problem of accuracy degradation. They do this by using skip connections, meaning they jump over layers.\n\nTo understand Resnets better please read the following links:\n\nhttps://towardsdatascience.com/hitchhikers-guide-to-residual-networks-resnet-in-keras-385ec01ec8ff\n\nhttps://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec","metadata":{}},{"cell_type":"markdown","source":"## Model 1\n\nresnet as base model, input shape = (32,32,3)","metadata":{}},{"cell_type":"code","source":"model_1=Sequential()\n#Add the Dense layers along with activation and batch normalization\nmodel_1.add(base_model_1)\n# model_1.add(Flatten())\nmodel_1.add(GlobalAveragePooling2D())\nmodel_1.add(Dropout(.25))\nmodel_1.add(Dense(256, activation='relu'))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Dense(100, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:06.834422Z","iopub.execute_input":"2024-06-03T02:03:06.834933Z","iopub.status.idle":"2024-06-03T02:03:17.331677Z","shell.execute_reply.started":"2024-06-03T02:03:06.834865Z","shell.execute_reply":"2024-06-03T02:03:17.330927Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model_1.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:18.740473Z","iopub.execute_input":"2024-06-03T02:03:18.740863Z","iopub.status.idle":"2024-06-03T02:03:18.756020Z","shell.execute_reply.started":"2024-06-03T02:03:18.740796Z","shell.execute_reply":"2024-06-03T02:03:18.754907Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 1, 1, 2048)        23587712  \n_________________________________________________________________\nglobal_average_pooling2d_5 ( (None, 2048)              0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 256)               524544    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 256)               1024      \n_________________________________________________________________\ndense_15 (Dense)             (None, 100)               25700     \n=================================================================\nTotal params: 24,138,980\nTrainable params: 24,085,348\nNon-trainable params: 53,632\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Immediately the first differences we see are that ResNet50 has a little more than 16 million extra parameters to train which is to be expected since it is a deeper model. Also, the number of units before the Flatten layer are 4 times that of the previous model.","metadata":{}},{"cell_type":"code","source":"#Compile the model \n\nmodel_1.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:24.856605Z","iopub.execute_input":"2024-06-03T02:03:24.856926Z","iopub.status.idle":"2024-06-03T02:03:24.890043Z","shell.execute_reply.started":"2024-06-03T02:03:24.856882Z","shell.execute_reply":"2024-06-03T02:03:24.889361Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import time\nt0 = time.time()\nmodel_1.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size),\n                     epochs=10,steps_per_epoch=x_train.shape[0]//batch_size,\n                     validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),validation_steps=250,\n                      verbose=1)\nt1 = time.time()-t0","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:34.447801Z","iopub.execute_input":"2024-06-03T02:03:34.448145Z","iopub.status.idle":"2024-06-03T02:10:53.110970Z","shell.execute_reply.started":"2024-06-03T02:03:34.448079Z","shell.execute_reply":"2024-06-03T02:10:53.109517Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Epoch 1/10\n350/350 [==============================] - 67s 193ms/step - loss: 4.7063 - acc: 0.0110 - val_loss: 4.6399 - val_acc: 0.0109\nEpoch 2/10\n350/350 [==============================] - 40s 115ms/step - loss: 4.5937 - acc: 0.0120 - val_loss: 4.5963 - val_acc: 0.0134\nEpoch 3/10\n350/350 [==============================] - 40s 114ms/step - loss: 4.5638 - acc: 0.0158 - val_loss: 4.5421 - val_acc: 0.0133\nEpoch 4/10\n350/350 [==============================] - 41s 116ms/step - loss: 4.4967 - acc: 0.0189 - val_loss: 5.0367 - val_acc: 0.0175\nEpoch 5/10\n350/350 [==============================] - 40s 115ms/step - loss: 4.4451 - acc: 0.0244 - val_loss: 7.0788 - val_acc: 0.0222\nEpoch 6/10\n350/350 [==============================] - 40s 114ms/step - loss: 4.3196 - acc: 0.0319 - val_loss: 4.3538 - val_acc: 0.0277\nEpoch 7/10\n350/350 [==============================] - 40s 114ms/step - loss: 4.2365 - acc: 0.0401 - val_loss: 4.2470 - val_acc: 0.0385\nEpoch 8/10\n350/350 [==============================] - 40s 115ms/step - loss: 4.1774 - acc: 0.0438 - val_loss: 4.1773 - val_acc: 0.0437\nEpoch 9/10\n350/350 [==============================] - 40s 115ms/step - loss: 4.0882 - acc: 0.0563 - val_loss: 4.1337 - val_acc: 0.0544\nEpoch 10/10\n350/350 [==============================] - 40s 114ms/step - loss: 3.9854 - acc: 0.0695 - val_loss: 3.9885 - val_acc: 0.0724\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred=model_1.predict_classes(x_test)\ny_true=np.argmax(y_test,axis=1)\n\n#Compute the confusion matrix\nconfusion_mtx=confusion_matrix(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:16:23.921637Z","iopub.execute_input":"2024-06-03T02:16:23.921977Z","iopub.status.idle":"2024-06-03T02:16:35.220580Z","shell.execute_reply.started":"2024-06-03T02:16:23.921932Z","shell.execute_reply":"2024-06-03T02:16:35.219907Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"Testing Accuracy: \", accuracy_score(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:16:37.391281Z","iopub.execute_input":"2024-06-03T02:16:37.391613Z","iopub.status.idle":"2024-06-03T02:16:37.397681Z","shell.execute_reply.started":"2024-06-03T02:16:37.391557Z","shell.execute_reply":"2024-06-03T02:16:37.396757Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Testing Accuracy:  0.0697\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model 2\nresnet as base model, input shape = (224,224,3)","metadata":{}},{"cell_type":"code","source":"from keras.layers import GlobalAveragePooling2D,UpSampling2D\n\nmodel_2=Sequential()\n#Add the Dense layers along with activation and batch normalization\nmodel_2.add(UpSampling2D(size=(7, 7),interpolation='bilinear'))\nmodel_2.add(base_model_2)\nmodel_2.add(GlobalAveragePooling2D())\nmodel_2.add(Dropout(.25))\nmodel_2.add(Dense(256, activation='relu'))\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(100, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:10:19.680295Z","iopub.execute_input":"2024-06-03T01:10:19.680653Z","iopub.status.idle":"2024-06-03T01:10:19.687281Z","shell.execute_reply.started":"2024-06-03T01:10:19.680587Z","shell.execute_reply":"2024-06-03T01:10:19.686299Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model_2.build((None,32,32,3)) # `input_shape` is the shape of the input data\n                         # e.g. input_shape = (None, 32, 32, 3)\nmodel_2.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:10:22.923139Z","iopub.execute_input":"2024-06-03T01:10:22.923474Z","iopub.status.idle":"2024-06-03T01:10:30.744719Z","shell.execute_reply.started":"2024-06-03T01:10:22.923413Z","shell.execute_reply":"2024-06-03T01:10:30.743782Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:10:37.095822Z","iopub.execute_input":"2024-06-03T01:10:37.096123Z","iopub.status.idle":"2024-06-03T01:10:37.110659Z","shell.execute_reply.started":"2024-06-03T01:10:37.096080Z","shell.execute_reply":"2024-06-03T01:10:37.109670Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nup_sampling2d_4 (UpSampling2 (None, 224, 224, 3)       0         \n_________________________________________________________________\nresnet50 (Model)             (None, 7, 7, 2048)        23587712  \n_________________________________________________________________\nglobal_average_pooling2d_4 ( (None, 2048)              0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 256)               524544    \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 256)               1024      \n_________________________________________________________________\ndense_8 (Dense)              (None, 100)               25700     \n=================================================================\nTotal params: 24,138,980\nTrainable params: 24,085,348\nNon-trainable params: 53,632\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#import cv2\n#x_train_resized =  np.array([cv2.resize(img, (224, 224)) for img in x_train])\n#x_val_resized =  np.array([cv2.resize(img, (224, 224)) for img in x_val])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:55:56.831375Z","iopub.execute_input":"2024-06-03T00:55:56.831856Z","iopub.status.idle":"2024-06-03T00:56:07.953112Z","shell.execute_reply.started":"2024-06-03T00:55:56.831783Z","shell.execute_reply":"2024-06-03T00:56:07.952127Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import time\nt0 = time.time()\nmodel_2.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size),\n                     epochs=10,steps_per_epoch=x_train.shape[0]//batch_size,\n                     validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),validation_steps=250,\n                      verbose=1)\nt2 = time.time()-t0","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:10:42.528654Z","iopub.execute_input":"2024-06-03T01:10:42.528953Z","iopub.status.idle":"2024-06-03T01:53:00.953801Z","shell.execute_reply.started":"2024-06-03T01:10:42.528910Z","shell.execute_reply":"2024-06-03T01:53:00.952896Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/10\n350/350 [==============================] - 274s 782ms/step - loss: 2.7114 - acc: 0.3162 - val_loss: 2.5922 - val_acc: 0.3481\nEpoch 2/10\n350/350 [==============================] - 251s 716ms/step - loss: 1.6625 - acc: 0.5361 - val_loss: 2.6908 - val_acc: 0.3308\nEpoch 3/10\n350/350 [==============================] - 251s 716ms/step - loss: 1.3069 - acc: 0.6240 - val_loss: 2.1857 - val_acc: 0.4344\nEpoch 4/10\n350/350 [==============================] - 251s 716ms/step - loss: 1.0809 - acc: 0.6804 - val_loss: 1.7159 - val_acc: 0.5405\nEpoch 5/10\n350/350 [==============================] - 251s 717ms/step - loss: 0.9120 - acc: 0.7265 - val_loss: 2.1205 - val_acc: 0.4847\nEpoch 6/10\n350/350 [==============================] - 251s 716ms/step - loss: 0.7845 - acc: 0.7601 - val_loss: 1.5458 - val_acc: 0.5858\nEpoch 7/10\n350/350 [==============================] - 250s 715ms/step - loss: 0.6631 - acc: 0.7955 - val_loss: 2.0495 - val_acc: 0.5251\nEpoch 8/10\n350/350 [==============================] - 250s 715ms/step - loss: 0.5628 - acc: 0.8228 - val_loss: 1.4037 - val_acc: 0.6331\nEpoch 9/10\n350/350 [==============================] - 250s 716ms/step - loss: 0.4934 - acc: 0.8445 - val_loss: 1.6709 - val_acc: 0.5956\nEpoch 10/10\n350/350 [==============================] - 251s 716ms/step - loss: 0.4337 - acc: 0.8599 - val_loss: 1.4864 - val_acc: 0.6329\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred=model_2.predict_classes(x_test)\ny_true=np.argmax(y_test,axis=1)\n\n#Compute the confusion matrix\nconfusion_mtx=confusion_matrix(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:56:09.260085Z","iopub.execute_input":"2024-06-03T01:56:09.260394Z","iopub.status.idle":"2024-06-03T01:56:33.097063Z","shell.execute_reply.started":"2024-06-03T01:56:09.260350Z","shell.execute_reply":"2024-06-03T01:56:33.096317Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(\"Testing Accuracy: \", accuracy_score(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T01:56:40.489064Z","iopub.execute_input":"2024-06-03T01:56:40.489390Z","iopub.status.idle":"2024-06-03T01:56:40.496382Z","shell.execute_reply.started":"2024-06-03T01:56:40.489343Z","shell.execute_reply":"2024-06-03T01:56:40.495345Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Testing Accuracy:  0.6214\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model 3\nefficientnet as base model, input = (224,224,3)","metadata":{}},{"cell_type":"code","source":"#!pip install -U efficientnet","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:32:46.145817Z","iopub.execute_input":"2024-06-03T02:32:46.146164Z","iopub.status.idle":"2024-06-03T02:32:52.325227Z","shell.execute_reply.started":"2024-06-03T02:32:46.146107Z","shell.execute_reply":"2024-06-03T02:32:52.324407Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from efficientnet) (0.15.0)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from efficientnet) (1.0.7)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.9.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.16.2)\nRequirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (0.5.2)\nRequirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (5.1.0)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (2.1)\nRequirement already satisfied: imageio>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (2.3.0)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (3.0.3)\nRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.0.1)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.6.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.2.0)\nRequirement already satisfied: decorator>=4.1.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.3.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (39.1.0)\nInstalling collected packages: efficientnet\nSuccessfully installed efficientnet-1.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import efficientnet.keras as effnet\nbase_model_3 = effnet.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n\nmodel_3 = Sequential()\nmodel_3.add(UpSampling2D(size=(7, 7),interpolation='bilinear'))\nmodel_3.add(base_model_3)\nmodel_3.add(GlobalAveragePooling2D())\nmodel_3.add(Dropout(.25))\nmodel_3.add(Dense(256, activation='relu'))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dense(100, activation='softmax'))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:34:14.349476Z","iopub.execute_input":"2024-06-03T02:34:14.349807Z","iopub.status.idle":"2024-06-03T02:34:47.652514Z","shell.execute_reply.started":"2024-06-03T02:34:14.349761Z","shell.execute_reply":"2024-06-03T02:34:47.651829Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model_3.build((None,32,32,3)) # `input_shape` is the shape of the input data\n                         # e.g. input_shape = (None, 32, 32, 3)\nmodel_3.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:34:47.654037Z","iopub.execute_input":"2024-06-03T02:34:47.654295Z","iopub.status.idle":"2024-06-03T02:35:00.681726Z","shell.execute_reply.started":"2024-06-03T02:34:47.654244Z","shell.execute_reply":"2024-06-03T02:35:00.680834Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model_3.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T03:24:51.010445Z","iopub.execute_input":"2024-06-03T03:24:51.011120Z","iopub.status.idle":"2024-06-03T03:24:51.025871Z","shell.execute_reply.started":"2024-06-03T03:24:51.010832Z","shell.execute_reply":"2024-06-03T03:24:51.024809Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nup_sampling2d_6 (UpSampling2 (None, 224, 224, 3)       0         \n_________________________________________________________________\nefficientnet-b0 (Model)      (None, 7, 7, 1280)        4049564   \n_________________________________________________________________\nglobal_average_pooling2d_7 ( (None, 1280)              0         \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 1280)              0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 256)               327936    \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 256)               1024      \n_________________________________________________________________\ndense_19 (Dense)             (None, 100)               25700     \n=================================================================\nTotal params: 4,404,224\nTrainable params: 4,361,696\nNon-trainable params: 42,528\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"t0 = time.time()\nmodel_3.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size),\n                     epochs=10,steps_per_epoch=x_train.shape[0]//batch_size,\n                     validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),validation_steps=250,\n                      verbose=1)\nt3 = time.time()-t0","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:35:07.736898Z","iopub.execute_input":"2024-06-03T02:35:07.737222Z","iopub.status.idle":"2024-06-03T03:20:55.451606Z","shell.execute_reply.started":"2024-06-03T02:35:07.737171Z","shell.execute_reply":"2024-06-03T03:20:55.450835Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Epoch 1/10\n350/350 [==============================] - 308s 879ms/step - loss: 2.8905 - acc: 0.2805 - val_loss: 2.3785 - val_acc: 0.3785\nEpoch 2/10\n350/350 [==============================] - 271s 773ms/step - loss: 1.6806 - acc: 0.5193 - val_loss: 1.7612 - val_acc: 0.5158\nEpoch 3/10\n350/350 [==============================] - 270s 771ms/step - loss: 1.2747 - acc: 0.6289 - val_loss: 1.4293 - val_acc: 0.5951\nEpoch 4/10\n350/350 [==============================] - 269s 768ms/step - loss: 1.0227 - acc: 0.6908 - val_loss: 1.2560 - val_acc: 0.6464\nEpoch 5/10\n350/350 [==============================] - 269s 767ms/step - loss: 0.8426 - acc: 0.7417 - val_loss: 1.2065 - val_acc: 0.6601\nEpoch 6/10\n350/350 [==============================] - 270s 772ms/step - loss: 0.6972 - acc: 0.7834 - val_loss: 1.1419 - val_acc: 0.6815\nEpoch 7/10\n350/350 [==============================] - 270s 772ms/step - loss: 0.5898 - acc: 0.8144 - val_loss: 1.1815 - val_acc: 0.6775\nEpoch 8/10\n350/350 [==============================] - 270s 772ms/step - loss: 0.4862 - acc: 0.8439 - val_loss: 1.3053 - val_acc: 0.6668\nEpoch 9/10\n350/350 [==============================] - 270s 772ms/step - loss: 0.4228 - acc: 0.8618 - val_loss: 1.3356 - val_acc: 0.6618\nEpoch 10/10\n350/350 [==============================] - 271s 773ms/step - loss: 0.3578 - acc: 0.8836 - val_loss: 1.2534 - val_acc: 0.6844\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred=model_3.predict_classes(x_test)\ny_true=np.argmax(y_test,axis=1)\nprint(\"Testing Accuracy: \", accuracy_score(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T03:22:18.137393Z","iopub.execute_input":"2024-06-03T03:22:18.137734Z","iopub.status.idle":"2024-06-03T03:22:44.930668Z","shell.execute_reply.started":"2024-06-03T03:22:18.137691Z","shell.execute_reply":"2024-06-03T03:22:44.929447Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Testing Accuracy:  0.6899\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model 4\nFreeze","metadata":{}},{"cell_type":"code","source":"base_model_3.trainable = False\nmodel_4 = Sequential()\nmodel_4.add(UpSampling2D(size=(7, 7),interpolation='bilinear'))\nmodel_4.add(base_model_3)\nmodel_4.add(GlobalAveragePooling2D())\nmodel_4.add(Dropout(.25))\nmodel_4.add(Dense(256, activation='relu'))\nmodel_4.add(BatchNormalization())\nmodel_4.add(Dense(100, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T03:28:40.958439Z","iopub.execute_input":"2024-06-03T03:28:40.958797Z","iopub.status.idle":"2024-06-03T03:28:40.965758Z","shell.execute_reply.started":"2024-06-03T03:28:40.958750Z","shell.execute_reply":"2024-06-03T03:28:40.964874Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model_4.build((None,32,32,3)) # `input_shape` is the shape of the input data\n                         # e.g. input_shape = (None, 32, 32, 3)\nmodel_4.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T03:28:40.967016Z","iopub.execute_input":"2024-06-03T03:28:40.967236Z","iopub.status.idle":"2024-06-03T03:28:54.732130Z","shell.execute_reply.started":"2024-06-03T03:28:40.967199Z","shell.execute_reply":"2024-06-03T03:28:54.731292Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"model_4.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T03:29:05.919990Z","iopub.execute_input":"2024-06-03T03:29:05.920288Z","iopub.status.idle":"2024-06-03T03:29:05.934095Z","shell.execute_reply.started":"2024-06-03T03:29:05.920244Z","shell.execute_reply":"2024-06-03T03:29:05.932848Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nup_sampling2d_7 (UpSampling2 (None, 224, 224, 3)       0         \n_________________________________________________________________\nefficientnet-b0 (Model)      (None, 7, 7, 1280)        4049564   \n_________________________________________________________________\nglobal_average_pooling2d_8 ( (None, 1280)              0         \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 1280)              0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 256)               327936    \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 256)               1024      \n_________________________________________________________________\ndense_21 (Dense)             (None, 100)               25700     \n=================================================================\nTotal params: 4,404,224\nTrainable params: 354,148\nNon-trainable params: 4,050,076\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"t0 = time.time()\nmodel_4.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size),\n                     epochs=10,steps_per_epoch=x_train.shape[0]//batch_size,\n                     validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),validation_steps=250,\n                      verbose=1)\nt4 = time.time()-t0","metadata":{"execution":{"iopub.status.busy":"2024-06-03T03:29:35.237809Z","iopub.execute_input":"2024-06-03T03:29:35.238100Z","iopub.status.idle":"2024-06-03T03:43:03.916972Z","shell.execute_reply.started":"2024-06-03T03:29:35.238059Z","shell.execute_reply":"2024-06-03T03:43:03.916048Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Epoch 1/10\n350/350 [==============================] - 105s 300ms/step - loss: 0.5788 - acc: 0.8305 - val_loss: 1.2146 - val_acc: 0.6995\nEpoch 2/10\n350/350 [==============================] - 78s 222ms/step - loss: 0.3061 - acc: 0.9032 - val_loss: 1.2438 - val_acc: 0.7026\nEpoch 3/10\n350/350 [==============================] - 78s 222ms/step - loss: 0.2647 - acc: 0.9140 - val_loss: 1.2663 - val_acc: 0.7040\nEpoch 4/10\n350/350 [==============================] - 77s 221ms/step - loss: 0.2309 - acc: 0.9241 - val_loss: 1.2886 - val_acc: 0.7071\nEpoch 5/10\n350/350 [==============================] - 77s 221ms/step - loss: 0.2160 - acc: 0.9297 - val_loss: 1.3072 - val_acc: 0.7076\nEpoch 6/10\n350/350 [==============================] - 78s 223ms/step - loss: 0.2030 - acc: 0.9336 - val_loss: 1.3006 - val_acc: 0.7103\nEpoch 7/10\n350/350 [==============================] - 77s 221ms/step - loss: 0.1895 - acc: 0.9361 - val_loss: 1.3385 - val_acc: 0.7076\nEpoch 8/10\n350/350 [==============================] - 79s 226ms/step - loss: 0.1732 - acc: 0.9425 - val_loss: 1.3508 - val_acc: 0.7120\nEpoch 9/10\n350/350 [==============================] - 79s 226ms/step - loss: 0.1785 - acc: 0.9401 - val_loss: 1.3405 - val_acc: 0.7141\nEpoch 10/10\n350/350 [==============================] - 80s 228ms/step - loss: 0.1640 - acc: 0.9467 - val_loss: 1.3685 - val_acc: 0.7131\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred=model_4.predict_classes(x_test)\ny_true=np.argmax(y_test,axis=1)\nprint(\"Testing Accuracy: \", accuracy_score(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T03:45:57.855459Z","iopub.execute_input":"2024-06-03T03:45:57.855849Z","iopub.status.idle":"2024-06-03T03:46:24.311809Z","shell.execute_reply.started":"2024-06-03T03:45:57.855796Z","shell.execute_reply":"2024-06-03T03:46:24.310915Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Testing Accuracy:  0.7153\n","output_type":"stream"}]},{"cell_type":"code","source":"print(t1)\nprint(t2)\nprint(t3)\nprint(t4)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T03:47:22.302556Z","iopub.execute_input":"2024-06-03T03:47:22.302866Z","iopub.status.idle":"2024-06-03T03:47:22.308353Z","shell.execute_reply.started":"2024-06-03T03:47:22.302827Z","shell.execute_reply":"2024-06-03T03:47:22.307385Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"438.65637826919556\n2538.4194946289062\n2747.7093801498413\n808.6735408306122\n","output_type":"stream"}]}]}